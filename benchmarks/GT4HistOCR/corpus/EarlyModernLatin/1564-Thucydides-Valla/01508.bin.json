{
  "mistral-small": {
    "gt": "25",
    "response": "ſ",
    "wer": 100.0,
    "cer": 100.0,
    "accuracy": 0.0,
    "time": 1.261883020401001,
    "diffs": [
      [
        -1,
        "25"
      ],
      [
        1,
        "ſ"
      ]
    ],
    "matches": 0,
    "deletions": 2,
    "insertions": 1
  },
  "llama-4-maverick-17b": {
    "gt": "25",
    "response": "23",
    "wer": 100.0,
    "cer": 50.0,
    "accuracy": 50.0,
    "time": 1.2524919509887695,
    "diffs": [
      [
        0,
        "2"
      ],
      [
        -1,
        "5"
      ],
      [
        1,
        "3"
      ]
    ],
    "matches": 1,
    "deletions": 1,
    "insertions": 1
  },
  "spotlight": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 1.646704912185669,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "gpt-4.1": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 2.361543893814087,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "gpt-4o": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 2.519075870513916,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "o4-mini": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 2.9374752044677734,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "claude-4-opus": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 3.1397511959075928,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "qwen-2.5-vl-72b": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 3.6091957092285156,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "claude-4-sonnet": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 4.712978839874268,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "gemini-2.5-pro": {
    "gt": "25",
    "response": "2 5",
    "wer": 100.0,
    "cer": 50.0,
    "accuracy": 66.66666666666666,
    "time": 15.260806798934937,
    "diffs": [
      [
        0,
        "2"
      ],
      [
        1,
        " "
      ],
      [
        0,
        "5"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 1
  },
  "gpt-5-mini": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 2.8138771057128906,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "gpt-5": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 6.608133792877197,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "glm-4.5v": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 1.6811549663543701,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "gemini-2.5-flash": {
    "gt": "25",
    "response": "2⸗",
    "wer": 100.0,
    "cer": 50.0,
    "accuracy": 50.0,
    "time": 1.729187250137329,
    "diffs": [
      [
        0,
        "2"
      ],
      [
        -1,
        "5"
      ],
      [
        1,
        "⸗"
      ]
    ],
    "matches": 1,
    "deletions": 1,
    "insertions": 1
  },
  "mistral-medium-3.1": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 0.901893138885498,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "ernie-4.5-vl-28b-a3b": {
    "gt": "25",
    "response": "ꝥ",
    "wer": 100.0,
    "cer": 100.0,
    "accuracy": 0.0,
    "time": 1.9813971519470215,
    "diffs": [
      [
        -1,
        "25"
      ],
      [
        1,
        "ꝥ"
      ]
    ],
    "matches": 0,
    "deletions": 2,
    "insertions": 1
  },
  "grok-4": {
    "gt": "25",
    "response": "2 ſ",
    "wer": 100.0,
    "cer": 100.0,
    "accuracy": 33.33333333333333,
    "time": 11.042007684707642,
    "diffs": [
      [
        0,
        "2"
      ],
      [
        -1,
        "5"
      ],
      [
        1,
        " ſ"
      ]
    ],
    "matches": 1,
    "deletions": 1,
    "insertions": 2
  },
  "cogito-v2-109b": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 1.62178373336792,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  },
  "qwen3-vl-235b-instruct": {
    "gt": "25",
    "response": "25",
    "wer": 0.0,
    "cer": 0.0,
    "accuracy": 100.0,
    "time": 1.605273962020874,
    "diffs": [
      [
        0,
        "25"
      ]
    ],
    "matches": 2,
    "deletions": 0,
    "insertions": 0
  }
}